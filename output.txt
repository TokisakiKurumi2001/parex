['supervised', 'supervisory', 'learning', 'training', 'input']
BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.0591, -0.2259, -0.1931,  ...,  0.2030, -0.1762, -0.1944],
         [-0.5181, -0.1603, -0.6529,  ...,  0.3401,  0.9018, -1.2168],
         [-0.6834, -0.2194, -0.6277,  ...,  0.4826,  0.1279, -0.4472],
         ...,
         [-0.2193, -0.1090,  0.0741,  ...,  0.2937,  0.1188, -0.0598],
         [ 0.7301, -0.0570, -0.1729,  ..., -0.5840, -1.3127, -1.1288],
         [ 0.2060, -0.5919,  0.0527,  ...,  0.6790, -0.0474, -0.1538]]]), pooler_output=tensor([[ 0.0472, -0.0148, -0.0264,  0.0146, -0.0368, -0.0862,  0.0890,  0.0473,
         -0.0399,  0.0062,  0.0373,  0.0554, -0.0441, -0.0207,  0.0197, -0.0376,
          0.0469, -0.0375, -0.0538,  0.0807, -0.0026, -0.0112,  0.0014, -0.0838,
          0.0121,  0.0791, -0.0156,  0.0242,  0.0183,  0.0795,  0.0433,  0.0706,
         -0.0682,  0.0338, -0.0216, -0.0542, -0.0505,  0.0737, -0.0612, -0.0007,
          0.0160,  0.0242, -0.0774,  0.0932,  0.0091, -0.0090, -0.0805, -0.0073,
          0.0108,  0.0042, -0.1323,  0.0528, -0.0222, -0.0347, -0.0583, -0.0126,
          0.0086,  0.0448,  0.0768,  0.0476,  0.0798, -0.0030, -0.0409, -0.0156,
         -0.1034,  0.0016,  0.0271, -0.0613, -0.0029, -0.0363, -0.0229, -0.0414,
          0.0239,  0.0560,  0.0106,  0.0740, -0.0370,  0.0627, -0.1448,  0.0130,
          0.0592,  0.0806,  0.1083, -0.1136, -0.0649, -0.0288, -0.0283,  0.0673,
         -0.0005,  0.0635,  0.0519, -0.0294, -0.1353,  0.0641,  0.1033,  0.0003,
          0.0143, -0.0026, -0.1512,  0.0203,  0.0435, -0.0150,  0.0103,  0.0476,
          0.0593, -0.0120, -0.0603,  0.1019,  0.0183, -0.0525,  0.0096,  0.0009,
          0.0589,  0.0383, -0.0489,  0.0722, -0.0955, -0.0373, -0.0738,  0.0478,
          0.0749, -0.0975,  0.0216, -0.0129,  0.0645, -0.0224,  0.0464, -0.1466,
         -0.0673, -0.0235,  0.1751, -0.0560, -0.0012, -0.1187, -0.1266,  0.0048,
         -0.0382, -0.0253, -0.0742,  0.0624,  0.0346, -0.0815,  0.0041, -0.0335,
          0.0741,  0.0327, -0.0911, -0.1203, -0.0184, -0.0912,  0.0368, -0.0777,
         -0.0847,  0.0859,  0.0186,  0.0267,  0.1174,  0.0246, -0.0236, -0.1023,
         -0.0758, -0.0718,  0.0578,  0.0248, -0.0303,  0.0266,  0.0691, -0.0572,
          0.0035, -0.0685, -0.0481, -0.0589, -0.0238, -0.1072,  0.0360,  0.0120,
          0.0071, -0.0542,  0.0058, -0.0454,  0.0279, -0.0761, -0.0844, -0.0860,
          0.0681,  0.0646,  0.0371,  0.0408,  0.0935, -0.0716,  0.0191,  0.0009,
          0.0214,  0.0231, -0.0008, -0.0421, -0.1365,  0.0345,  0.1200, -0.0832,
         -0.0208,  0.0606,  0.0310,  0.0856, -0.0279, -0.0167, -0.0828, -0.1256,
          0.0092,  0.0796,  0.0957,  0.0754,  0.0132, -0.0614, -0.0868, -0.0481,
          0.0589,  0.0610,  0.0150,  0.0025,  0.0290, -0.0244,  0.0744, -0.1207,
         -0.0759,  0.0162, -0.0086, -0.0549,  0.0359, -0.0291, -0.0069,  0.0727,
          0.0558,  0.1518, -0.0146,  0.0666, -0.0660,  0.0136,  0.0878,  0.0586,
         -0.0684,  0.0510,  0.0168,  0.0257, -0.1072,  0.0920,  0.1376,  0.0196,
          0.0225, -0.0203,  0.0808, -0.0165,  0.0333,  0.0324, -0.0216,  0.0474,
          0.0015, -0.0030,  0.0076,  0.0933, -0.0333,  0.0396, -0.0616, -0.0094,
         -0.0891, -0.0185,  0.1511, -0.0317,  0.0417, -0.0585,  0.0521, -0.0115,
         -0.0537, -0.0190,  0.0808,  0.0401,  0.0799, -0.1578,  0.0532, -0.0696,
          0.0498,  0.0568,  0.0049, -0.0627,  0.0557, -0.0590,  0.0687,  0.0037,
          0.0484,  0.0874, -0.0251, -0.0297, -0.0234, -0.0199, -0.0410,  0.0671,
          0.0501,  0.0781,  0.0174,  0.0476, -0.0714, -0.0152,  0.0914, -0.0291,
         -0.0877, -0.0548, -0.0699,  0.0197, -0.0397,  0.0055,  0.0673,  0.0574,
         -0.0181,  0.1224, -0.0365, -0.0045,  0.0693, -0.1362,  0.0095,  0.0395,
         -0.0414, -0.0032,  0.0321,  0.0329,  0.0574,  0.0292,  0.0086,  0.0654,
         -0.0228,  0.0223,  0.0514,  0.0275,  0.0088,  0.1153,  0.0367, -0.1168,
          0.0885,  0.0056, -0.0135,  0.0353,  0.0702, -0.0055,  0.0212, -0.1354,
         -0.0017, -0.1280,  0.0179,  0.0140, -0.0040, -0.0098, -0.0438, -0.0810,
          0.0885, -0.0324, -0.0450, -0.0923, -0.0016,  0.0232,  0.0276, -0.0299,
          0.0224, -0.0406, -0.0543, -0.0537, -0.0300, -0.0031,  0.0080,  0.0092,
          0.0563,  0.0270, -0.0471,  0.0901,  0.1151,  0.0312, -0.0429,  0.0547,
         -0.1209,  0.0672, -0.0440, -0.0337, -0.0066,  0.0073, -0.0669,  0.0131]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)
last_hidden_state: torch.Size([1, 100, 384])
pooler_output: torch.Size([1, 384])
